{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt, exp, pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/spambase.csv').values\n",
    "X = data[:,:48]\n",
    "Y = data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX = X[:-100,]\n",
    "trainY = Y[:-100,]\n",
    "testX = X[-100:,]\n",
    "testY = Y[-100:,]\n",
    "\n",
    "\n",
    "all_classes = set(trainY)\n",
    "nbr_train_rows = len(trainY)\n",
    "nbr_elements_in_classes = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "- Naive Bayes Classification is based on the Naive Bayes Theorem :\n",
    "\n",
    "$$  P(\\textbf{Class}|\\textbf{Features}) = \\frac{P(\\textbf{Features} | \\textbf{Class}) P(\\textbf{Class})}{P(\\textbf{Features})} $$\n",
    "\n",
    "- When predicting the class we choose the class with highest probability\n",
    "\n",
    "$$  \\textbf{arg max}(\\textbf{Class})  P(\\textbf{Class}|\\textbf{Features}) = \\frac{P(\\textbf{Features} | \\textbf{Class}) P(\\textbf{Class})}{P(\\textbf{Features})} $$\n",
    "\n",
    "- We can ignore the denominator : $ P(\\textbf{Features}) $ because it's the same for all classes. We are left with : \n",
    "\n",
    "$$  \\textbf{arg max}(\\textbf{Class}) P(\\textbf{Class}|\\textbf{Features}) = P(\\textbf{Features} | \\textbf{Class}) P(\\textbf{Class}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian NB\n",
    "\n",
    "- To calculate $ P(\\textbf{Features}/\\textbf{Class})$ we use the Gaussian Probability Formula :\n",
    "<h3>\n",
    "$$\n",
    "P(\\textbf{f1 = x}/\\textbf{Class}) = {\\frac {1}{\\sqrt {2\\pi \\cdot \\sigma ^{2}}}}e^{-\\large{{\\frac {(x-\\mu )^{2}}{2 \\cdot \\sigma ^{2}}}}}\n",
    "$$\n",
    "</h3>\n",
    "\n",
    "- Calculate Means ($ \\mu $) and Standard Deviations ($ \\sigma $) for each Feature for each Class\n",
    "- Calculate Class Priors $ P(\\textbf{Class}) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0: 2688, 1.0: 1812}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "mean_features = {}\n",
    "sd_features = {}\n",
    "class_priors = {}\n",
    "\n",
    "for c in all_classes:\n",
    "    mean_features[c] = [0] * 48\n",
    "    sd_features[c] = [0] * 48\n",
    "    nbr_elements_in_classes[c] = len(list(filter(lambda x: x == c, trainY)))\n",
    "    class_priors[c] = nbr_elements_in_classes[c] / nbr_train_rows\n",
    "\n",
    "print (nbr_elements_in_classes)\n",
    "\n",
    "#print(sum_features)\n",
    "\n",
    "for f in range(48):\n",
    "    for r in range(nbr_train_rows):\n",
    "        c = trainY[r]\n",
    "        mean_features[c][f] += trainX[r][f]\n",
    "\n",
    "for c in mean_features:\n",
    "    for f in range(48):\n",
    "        mean_features[c][f] = mean_features[c][f] / nbr_elements_in_classes[c]\n",
    "\n",
    "\n",
    "#print (mean_features)\n",
    "\n",
    "for f in range(48):\n",
    "    for r in range(nbr_train_rows):\n",
    "        c = trainY[r]\n",
    "        sd_features[c][f] += ((trainX[r][f] - mean_features[c][f]) ** 2)\n",
    "\n",
    "for c in mean_features:\n",
    "    sd_features[c] = list(map(lambda x: sqrt(x / (nbr_elements_in_classes[c] - 1)), sd_features[c]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = [False] * len(testY)\n",
    "score = 0\n",
    "\n",
    "for i in range(len(testY)):\n",
    "    f_vector = testX[i]\n",
    "    correct_class = testY[i]\n",
    "    predictions = {}\n",
    "    max_val = 0\n",
    "    current_class = None\n",
    "    for c in all_classes:\n",
    "        predictions[c] = predict(f_vector, c)\n",
    "        if predictions[c] > max_val:\n",
    "            max_val = predictions[c]\n",
    "            current_class = c\n",
    "    results[i] = current_class == correct_class\n",
    "    if results[i]:\n",
    "        score += 1\n",
    "\n",
    "print(results)\n",
    "print(score/len(testY))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
