{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/spambase.csv').values\n",
    "X = data[:,:48]\n",
    "Y = data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX = X[:-100,]\n",
    "trainY = Y[:-100,]\n",
    "testX = X[-100:,]\n",
    "testY = Y[-100:,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "- Naive Bayes Classification is based on the Naive Bayes Theorem :\n",
    "\n",
    "$$  P(\\textbf{Class}|\\textbf{Features}) = \\frac{P(\\textbf{Features} | \\textbf{Class}) P(\\textbf{Class})}{P(\\textbf{Features})} $$\n",
    "\n",
    "- When predicting the class we choose the class with highest probability\n",
    "\n",
    "$$  \\textbf{arg max}(\\textbf{Class})  P(\\textbf{Class}|\\textbf{Features}) = \\frac{P(\\textbf{Features} | \\textbf{Class}) P(\\textbf{Class})}{P(\\textbf{Features})} $$\n",
    "\n",
    "- We can ignore the denominator : $ P(\\textbf{Features}) $ because it's the same for all classes. We are left with : \n",
    "\n",
    "$$  \\textbf{arg max}(\\textbf{Class}) P(\\textbf{Class}|\\textbf{Features}) = P(\\textbf{Features} | \\textbf{Class}) P(\\textbf{Class}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian NB\n",
    "\n",
    "- To calculate $ P(\\textbf{Features}/\\textbf{Class})$ we use the Gaussian Probability Formula :\n",
    "<h3>\n",
    "$$\n",
    "P(\\textbf{f1 = x}/\\textbf{Class}) = {\\frac {1}{\\sqrt {2\\pi \\cdot \\sigma ^{2}}}}e^{-\\large{{\\frac {(x-\\mu )^{2}}{2 \\cdot \\sigma ^{2}}}}}\n",
    "$$\n",
    "</h3>\n",
    "\n",
    "- Calculate Means ($ \\mu $) and Standard Deviations ($ \\sigma $) for each Feature for each Class\n",
    "- Calculate Class Priors $ P(\\textbf{Class}) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classes = set(trainY)\n",
    "nbr_train_rows = len(trainY)\n",
    "nbr_elements_in_classes = {}\n",
    "\n",
    "mean_features = {}\n",
    "sd_features = {}\n",
    "class_priors = {}\n",
    "\n",
    "for c in all_classes:\n",
    "    mean_features[c] = [0] * 48\n",
    "    sd_features[c] = [0] * 48\n",
    "    nbr_elements_in_classes[c] = len(list(filter(lambda x: x == c, trainY)))\n",
    "    class_priors = nbr_elements_in_classes[c] / nbr_train_rows\n",
    "\n",
    "print (nbr_elements_in_classes)\n",
    "\n",
    "#print(sum_features)\n",
    "\n",
    "for f in range(48):\n",
    "    for r in range(nbr_train_rows):\n",
    "        c = trainY[r]\n",
    "        mean_features[c][f] += trainX[r][f]\n",
    "\n",
    "for c in mean_features:\n",
    "    for f in range(48):\n",
    "        mean_features[c][f] = mean_features[c][f] / nbr_elements_in_classes[c]\n",
    "\n",
    "\n",
    "#print (mean_features)\n",
    "\n",
    "for f in range(48):\n",
    "    for r in range(nbr_train_rows):\n",
    "        c = trainY[r]\n",
    "        sd_features[c][f] += ((trainX[r][f] - mean_features[c][f]) ** 2)\n",
    "\n",
    "for c in mean_features:\n",
    "    sd_features[c] = list(map(lambda x: sqrt(x / (nbr_elements_in_classes[c] - 1)), sd_features[c]))\n",
    "\n",
    "#print (sd_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1df95977e4e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mcurrent_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mmax_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-1df95977e4e1>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(features, c)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mlikelyhood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mlikelyhood\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mgaussian\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmean_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msd_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlikelyhood\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mclass_priors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean_features' is not defined"
     ]
    }
   ],
   "source": [
    "# Test the model with the TestX and TestY sets\n",
    "\n",
    "def gaussian(mean, sd, x):\n",
    "    exponent = exp(-( ((x-mean)**2) / (2*(sd**2)) ))\n",
    "    res =  1 / sqrt( (2 * pi * (sd**2)) )\n",
    "    res *= exponent\n",
    "    return res\n",
    "\n",
    "def predict(features, c):\n",
    "    likelyhood = 1\n",
    "    for i in range(len(features)):\n",
    "        likelyhood *= gaussian (mean_features[c][i], sd_features[c][i], features[i])\n",
    "    return likelyhood * class_priors[c]\n",
    "\n",
    "results = [False] * len(testY)\n",
    "score = 0\n",
    "\n",
    "for i in range(len(testY)):\n",
    "    f_vector = testX[i]\n",
    "    correct_class = testY[i]\n",
    "    predictions = {}\n",
    "    max_val = 0\n",
    "    current_class = None\n",
    "    for c in all_classes:\n",
    "        predictions[c] = predict(f_vector, c)\n",
    "        if predictions[c] > max_val:\n",
    "            max_val = predictions[c]\n",
    "            current_class = c\n",
    "    results[i] = current_class == correct_class\n",
    "    if results[i]:\n",
    "        score += 1\n",
    "\n",
    "#print(results)\n",
    "print(score/len(testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
